{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fc7158-abbc-49a5-87d0-e75250401138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptify import Prompter\n",
    "from promptify import Model, Azure, AnthropicModel, CohereModel\n",
    "from promptify import Pipeline\n",
    "\n",
    "\n",
    "# model = Model() # 'all model related things will be handle here'\n",
    "# prompter = Prompter() # 'everything related to prompt will be handle here such as prompt versioning, multiple prompts etc'\n",
    "# pipe = Pipeline (model, prompter) # it takes one prompter and one model\n",
    "\n",
    "# model = Oapi_key = \"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\", model = \"gpt-4\")\n",
    "\n",
    "# model = Azure(api_key = '776adfa04e084cc69f2d58e33c684394',\n",
    "#              api_base = 'https://airesearch-dev.openai.azure.com/',\n",
    "#               api_type = 'azure',\n",
    "#               api_version = '2023-03-15-preview',\n",
    "#               engine = 'gpt35turbo',\n",
    "#               model = 'gpt-35-turbo')\n",
    "\n",
    "model = AnthropicModel(\"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\", \n",
    "                      model = 'claude-2')\n",
    "\n",
    "# model = CohereModel('w5zH0UbislRCxITc8UN8pJRQCcdcGq6nJZ8Nm4YL')\n",
    "prompter = Prompter('multilabel_classification.jinja')\n",
    "# prompter = Prompter('ner.jinja')\n",
    "pipe = Pipeline(prompter , model, structured_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f91a74-30ae-40ac-8964-576bd2e994f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd68e0f-9e7a-44d7-a0ed-3893aaa8fb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:05<00:00,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '[\"[{\\'main class\\': \\'vascular diseases\\', \\'1\\': \\'peripheral artery disease\\', \\'branch\\': \\'cardiology\\', \\'group\\': \\'circulatory system diseases\\'}]\"]', 'parsed': {'status': 'completed', 'object_type': <class 'list'>, 'data': {'completion': [\"[{'main class': 'vascular diseases', '1': 'peripheral artery disease', 'branch': 'cardiology', 'group': 'circulatory system diseases'}]\"], 'suggestions': []}}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pipe.fit(\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction. On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis, popliteal, and femoral pulses in both lower and and extremitiess\")\n",
    "\n",
    "\n",
    "print(pipe.fit(\"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremitiess \"\"\", \n",
    "         domain = 'medical',\n",
    "         labels = 'diagnosis', \n",
    "         n_output_labels = 5))\n",
    "\n",
    "\n",
    "#extract jons from text using regular expressions\n",
    "# foroutput like this\n",
    "\n",
    "# ok Completion(completion=\" Here is the NER output for the given medical passage:\\n\\n[{'T': 'diagnosis', 'E': 'pain'}, \\n{'T': 'diagnosis', 'E': 'numbness'},\\n{'T': 'diagnosis', 'E': 'tingling'},\\n{'T': 'diagnosis', 'E': 'erectile dysfunction'},\\n{'T': 'diagnosis', 'E': 'weak dorsalis pedis'},\\n{'T': 'diagnosis', 'E': 'tibialis'},\\n{'T': 'diagnosis', 'E': 'popliteal'},  \\n{'T': 'diagnosis', 'E': 'femoral pulses'},\\n{'branch' : 'Neurology' , 'group': 'Neuropathy'}]\", model='claude-2.0', stop_reason='stop_sequence', stop='\\n\\nHuman:', log_id='808b14cc65a6c88cb76c5e1dea7665c3ccd8d3081b4c5a3446f0b401eb2918a6')\n",
    "\n",
    "# gotit {'text': \"Here is the NER output for the given medical passage:\\n\\n[{'T': 'diagnosis', 'E': 'pain'}, \\n{'T': 'diagnosis', 'E': 'numbness'},\\n{'T': 'diagnosis', 'E': 'tingling'},\\n{'T': 'diagnosis', 'E': 'erectile dysfunction'},\\n{'T': 'diagnosis', 'E': 'weak dorsalis pedis'},\\n{'T': 'diagnosis', 'E': 'tibialis'},\\n{'T': 'diagnosis', 'E': 'popliteal'},  \\n{'T': 'diagnosis', 'E': 'femoral pulses'},\\n{'branch' : 'Neurology' , 'group': 'Neuropathy'}]\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# {'text': \"Here is the NER output for the given medical passage:\\n\\n[{'T': 'diagnosis', 'E': 'pain'}, {'T': 'diagnosis', 'E': 'numbness'}, {'T': 'diagnosis', 'E': 'tingling'}, {'T': 'diagnosis', 'E': 'erectile dysfunction'}, {'T': 'diagnosis', 'E': 'weak dorsalis pedis'}, {'T': 'diagnosis', 'E': 'tibialis'}, {'T': 'diagnosis', 'E': 'popliteal'}, {'T': 'diagnosis', 'E': 'femoral pulses'}, {'branch' : 'Vascular', 'group': 'Arterial'}]\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40086d5-45c2-4f9e-ac53-fa9effde7f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('w5zH0UbislRCxITc8UN8pJRQCcdcGq6nJZ8Nm4YL') # This is your trial API key\n",
    "\n",
    "prompt = \"\"\"give me named entities from this sentences, return output only in json format {'T': 'entity'}\"\"\"\n",
    "\n",
    "sen = prompt + \"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremities\"\"\"\n",
    "\n",
    "response = co.generate(\n",
    "  model='command', # other models [ command-light, command-medium-beta, command-nightly, command-xlarge-beta]\n",
    "  prompt=sen,\n",
    "  max_tokens=200,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE',\n",
    "stream = False,\n",
    "truncate = 'END', presence_penalty = 0.0,\n",
    "frequency_penalty = 0.0,\n",
    "p = 0.75,\n",
    "    num_generations = 1,\n",
    ")\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5be512-27ed-40f0-9f02-014a95e6c340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import cohere\n",
    "\n",
    "from promptify import Parser\n",
    "from promptify import Model\n",
    "\n",
    "class CohereModel(Model):\n",
    "    name = \"Cohere\"\n",
    "    description = \"Cohere API for text completion using Command model\"\n",
    "\n",
    "    SUPPORTED_MODELS = set(\n",
    "        [\n",
    "            \"command\", \n",
    "            \"command-light\", \n",
    "            \"command-medium-beta\", \n",
    "            \"command-nightly\", \n",
    "            \"command-xlarge-beta\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        model: str = \"command\",\n",
    "        temperature: float = 0.9,\n",
    "        top_k: int = 0,\n",
    "        max_tokens: int = 200,\n",
    "        stop_sequences: Optional[Union[str, List[str]]] = [],\n",
    "        return_likelihoods: str = 'NONE',\n",
    "        stream: bool = False,\n",
    "        truncate: str = 'END',\n",
    "        presence_penalty: float = 0.0,\n",
    "        frequency_penalty: float = 0.0,\n",
    "        top_p: float = 0.75,\n",
    "        num_generations: int = 1,\n",
    "        api_wait=60,\n",
    "        api_retry=6,\n",
    "        max_completion_length: int = 20\n",
    "    ):\n",
    "        super().__init__(api_key, model, api_wait, api_retry)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.top_k = top_k\n",
    "        self.max_tokens = max_tokens\n",
    "        self.stop_sequences = stop_sequences\n",
    "        self.return_likelihoods = return_likelihoods\n",
    "        self.max_completion_length = max_completion_length\n",
    "        self.stream = stream\n",
    "        self.truncate = truncate\n",
    "        self.presence_penalty = presence_penalty\n",
    "        self.frequency_penalty = frequency_penalty\n",
    "        self.top_p = top_p\n",
    "        self.num_generations = num_generations\n",
    "        self.set_key(api_key)\n",
    "        self._verify_model()\n",
    "        self.parameters = self.get_parameters()\n",
    "        self._initialize_parser()\n",
    "\n",
    "    def set_key(self, api_key: str):\n",
    "        self._cohere = cohere.Client(api_key)\n",
    "\n",
    "    def _verify_model(self):\n",
    "        if self.model not in self.SUPPORTED_MODELS:\n",
    "            raise ValueError(f\"Unsupported model: {self.model}\")\n",
    "            \n",
    "    def _initialize_parser(self):\n",
    "        self.parser = Parser()\n",
    "\n",
    "    def set_model(self, model: str):\n",
    "        self.model = model\n",
    "        self._verify_model()\n",
    "\n",
    "    def supported_models(self):\n",
    "        return list(self.SUPPORTED_MODELS)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"k\": self.top_k,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "            \"stop_sequences\": self.stop_sequences,\n",
    "            \"return_likelihoods\": self.return_likelihoods,\n",
    "            \"stream\": self.stream,\n",
    "            \"truncate\": self.truncate,\n",
    "            \"presence_penalty\": self.presence_penalty,\n",
    "            \"frequency_penalty\": self.frequency_penalty,\n",
    "            \"p\": self.top_p,\n",
    "            \"num_generations\": self.num_generations\n",
    "        }\n",
    "\n",
    "    def get_description(self):\n",
    "        return self.description\n",
    "\n",
    "    def get_endpoint(self):\n",
    "        return self.model\n",
    "\n",
    "    def run(self, prompt: str):\n",
    "        self.parameters[\"prompt\"] = prompt\n",
    "        response = self._cohere.generate(\n",
    "            model=self.model,\n",
    "            **self.parameters,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def model_output_raw(self, response: Dict) -> Dict:\n",
    "        data = {}\n",
    "        raw_response = response.generations[0].text.strip(\" \\n\")\n",
    "        data['text'] = str(raw_response)\n",
    "        return data\n",
    "    \n",
    "    def model_output(self, response, max_completion_length) -> Dict:\n",
    "        data = self.model_output_raw(response)\n",
    "        data[\"parsed\"] = self.parser.fit(data[\"text\"], max_completion_length)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64226349-a2a0-4430-b521-d13b864a56de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CohereModel('w5zH0UbislRCxITc8UN8pJRQCcdcGq6nJZ8Nm4YL')\n",
    "\n",
    "prompt = \"\"\"give me named entities from this sentences, return output only in json format {'T': 'entity'}\"\"\"\n",
    "\n",
    "sen = prompt + \"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremities\"\"\"\n",
    "\n",
    "\n",
    "model.model_output(model.run(sen), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2f814-3225-4e4e-9419-abf567d904e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "this is base model class\n",
    "\n",
    "\"\"\"from abc import ABCMeta, abstractmethod\n",
    "from typing import List, Optional, Union, Dict\n",
    "import tenacity\n",
    "\n",
    "\n",
    "class Model(metaclass=ABCMeta):\n",
    "\n",
    "    name = \"\"\n",
    "    description = \"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        model: str,\n",
    "        api_wait: int = 60,\n",
    "        api_retry: int = 6,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.api_wait = api_wait\n",
    "        self.api_retry = api_retry\n",
    "        self._verify_model()\n",
    "        self.set_key(api_key)\n",
    "\n",
    "    @abstractmethod\n",
    "    def supported_models(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def _verify_model(self):\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_key(self, api_key: str):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_model(self, model: str):\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_description(self) -> str:\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_endpoint(self) -> str:\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_parameters(self) -> Dict[str, str]:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def run(self, prompts: List[str]) -> List[str]:\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def model_output(self, response):\n",
    "        \n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _retry_decorator(self):\n",
    "       \n",
    "        return tenacity.retry(\n",
    "            wait=tenacity.wait_random_exponential(\n",
    "                multiplier=0.3, exp_base=3, max=self.api_wait\n",
    "            ),\n",
    "            stop=tenacity.stop_after_attempt(self.api_retry),\n",
    "        )\n",
    "\n",
    "    def execute_with_retry(self, *args, **kwargs):\n",
    "        \n",
    "        decorated_run = self._retry_decorator()(self.run)\n",
    "        return decorated_run(*args, **kwargs)\n",
    "\"\"\"\n",
    "\n",
    "I derived one Anthropic model class\n",
    "\n",
    "\n",
    "\"\"\"from typing import Dict, List, Optional, Tuple, Union\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "from promptify.parser.parser import Parser\n",
    "from promptify.models.text2text.api.base_model import Model\n",
    "import re\n",
    "\n",
    "class AnthropicModel(Model):\n",
    "    name = \"Anthropic\"\n",
    "    description = \"Anthropic API for text completion using Claude model\"\n",
    "\n",
    "    SUPPORTED_MODELS = set(\n",
    "        [\n",
    "            \"claude-instant-1\",\n",
    "            \"claude-2\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    POSSIBLE_PREFIX = ['here are', 'here is', 'following are']\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        model: str = \"claude-instant-1\",\n",
    "        temperature: float = 1,\n",
    "        top_p: float = 0.7,\n",
    "        top_k: int = 5,\n",
    "        max_tokens_to_sample: int = 300,\n",
    "        stop_sequences: Optional[Union[str, List[str]]] = [\"\\n\\nHuman:\"],\n",
    "        api_wait=60,\n",
    "        api_retry=6,\n",
    "        max_completion_length: int = 20\n",
    "    ):\n",
    "        super().__init__(api_key, model, api_wait, api_retry)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.top_k = top_k\n",
    "        self.max_tokens_to_sample = max_tokens_to_sample\n",
    "        self.max_completion_length = max_completion_length\n",
    "        self.stop_sequences = stop_sequences\n",
    "        self.set_key(api_key)\n",
    "        self._verify_model()\n",
    "        self.parameters = self.get_parameters()\n",
    "        \n",
    "        self.max_completion_length = max_completion_length\n",
    "        self._initialize_parser()\n",
    "\n",
    "    def set_key(self, api_key: str):\n",
    "        self._anthropic = Anthropic(api_key=api_key)\n",
    "\n",
    "    def _verify_model(self):\n",
    "        if self.model not in self.SUPPORTED_MODELS:\n",
    "            raise ValueError(f\"Unsupported model: {self.model}\")\n",
    "\n",
    "    def set_model(self, model: str):\n",
    "        self.model = model\n",
    "        self._verify_model()\n",
    "\n",
    "    def _initialize_parser(self):\n",
    "        self.parser = Parser()\n",
    "\n",
    "    def supported_models(self):\n",
    "        return list(self.SUPPORTED_MODELS)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"max_tokens_to_sample\": self.max_tokens_to_sample,\n",
    "            \"stop_sequences\": self.stop_sequences,\n",
    "        }\n",
    "\n",
    "    def get_description(self):\n",
    "        return self.description\n",
    "\n",
    "    def get_endpoint(self):\n",
    "        return self.model\n",
    "\n",
    "    def run(self, prompt: str):\n",
    "        self.parameters[\"prompt\"] = f\"{HUMAN_PROMPT} {prompt} {AI_PROMPT}\"\n",
    "        response = self._anthropic.completions.create(\n",
    "            model=self.model,\n",
    "            **self.parameters,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def model_output_raw(self, response: Dict) -> Dict:\n",
    "        data = {}\n",
    "        raw_response = response.completion.strip(\" \\n\")\n",
    "        data['text'] = str(raw_response)\n",
    "        return data\n",
    "\n",
    "    def model_output(self, response, max_completion_length) -> Dict:\n",
    "        data = self.model_output_raw(response)\n",
    "        data[\"parsed\"] = self.parser.fit(data[\"text\"], max_completion_length)\n",
    "        return data\"\"\"\n",
    "\n",
    "\n",
    "Now derived one class for below function same way as openai while considering base class too\n",
    " \n",
    "\"\"\"import cohere\n",
    "co = cohere.Client('key') # This is your trial API key\n",
    "\n",
    "prompt = \"\"\"give me named entities from this sentences, return output only in json format {'T': 'entity'}\"\"\"\n",
    "\n",
    "\n",
    "response = co.generate(\n",
    "  model='command', # other models [ command-light, command-medium-beta, command-nightly, command-xlarge-beta]\n",
    "  prompt=sen,\n",
    "  max_tokens=200,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE',\n",
    "stream = False,\n",
    "truncate = 'END', presence_penalty = 0.0,\n",
    "frequency_penalty = 0.0,\n",
    "p = 0.75,\n",
    "    num_generations = 1,\n",
    ")\n",
    "response.generations[0].text)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115df83-a8e6-47fa-a208-21b35ffe8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "co.generate().__dir__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6290599-c4a7-4b6a-841a-c2f1775b3339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d0e9e-8525-4a03-98ed-ffa0e0be40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import re\n",
    "fg = \"\"\"Here are the named entities found in the given passage:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"T\": \"diagnosis\", \n",
    "    \"E\": \"pain, numbness, and tingling in both lower extremities\"\n",
    "  },\n",
    "  {\n",
    "    \"T\": \"diagnosis\",\n",
    "    \"E\": \"erectile dysfunction\"\n",
    "  },\n",
    "  {\n",
    "    \"T\": \"diagnosis\", \n",
    "    \"E\": \"weak dorsalis pedis, tibialis, popliteal, and femoral pulses in both lower and and extremitiess\"\n",
    "  },\n",
    "  {\n",
    "   \"branch\": \"Cardiology\",\n",
    "   \"group\": \"Vascular Disease\"\n",
    "  }\n",
    "]\"\"\"\n",
    "\n",
    "POSSIBLE_PREFIX = ['here are', 'here is', 'following are']\n",
    "\n",
    "def extract_string_json(text):\n",
    "    pattern = r'\\[\\s*(\\{.*?\\})\\s*\\]'\n",
    "    match = re.search(pattern, text, flags=re.S)\n",
    "    print(match)\n",
    "    if match:\n",
    "        try:\n",
    "            return match.group()\n",
    "        except Exception as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "\n",
    "# string_json = []\n",
    "# for prefix in POSSIBLE_PREFIX:\n",
    "#     if prefix in fg.lower():\n",
    "#         string_json.append(extract_string_json(str(fg)))\n",
    "#         break\n",
    "        \n",
    "# string_json\n",
    "\n",
    "eval(extract_string_json(fg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7de1c6-fe80-4022-9f23-97b1c86a9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_and_load_json(text):\n",
    "    pattern = r'(\\{.*?\\}|\\[.*?\\])'\n",
    "    match = re.search(pattern, text, flags=re.S)\n",
    "    print(match)\n",
    "    if match:\n",
    "        try:\n",
    "            return match.group()\n",
    "        except Exception as e:\n",
    "            print(f\"Error decoding JSON: {e}\")\n",
    "            return None\n",
    "\n",
    "# Example usage:\n",
    "text = \"\"\"Here are the named entities found in the given passage:\n",
    "\n",
    "{ 'ere' : [\n",
    "  {'T': 'diagnosis', 'E': 'pain'},\n",
    "  {'T': 'diagnosis', 'E': 'numbness'}, \n",
    "  {'T': 'diagnosis', 'E': 'tingling'},\n",
    "  {'T': 'diagnosis', 'E': 'erectile dysfunction'},\n",
    "  {'T': 'diagnosis', 'E': 'weak dorsalis pedis'},\n",
    "  {'T': 'diagnosis', 'E': 'tibialis'},\n",
    "  {'T': 'diagnosis', 'E': 'popliteal'}, \n",
    "  {'T': 'diagnosis', 'E': 'femoral pulses'}\n",
    "]}\"\"\"\n",
    "json_objects = extract_and_load_json(text)\n",
    "print(json_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece0811-bc1d-459f-8ffd-d92a373201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"Here are the named entities found in the given passage:\n",
    "\n",
    "[\n",
    "  {'T': 'diagnosis', 'E': 'pain'},\n",
    "  {'T': 'diagnosis', 'E': 'numbness'}, \n",
    "  {'T': 'diagnosis', 'E': 'tingling'},\n",
    "  {'T': 'diagnosis', 'E': 'erectile dysfunction'},\n",
    "  {'T': 'diagnosis', 'E': 'weak dorsalis pedis'},\n",
    "  {'T': 'diagnosis', 'E': 'tibialis'},\n",
    "  {'T': 'diagnosis', 'E': 'popliteal'}, \n",
    "  {'T': 'diagnosis', 'E': 'femoral pulses'}\n",
    "]\"\"\"\n",
    "\n",
    "pattern = r'(\\[.*?\\])'\n",
    "match = re.search(pattern, text, flags=re.S)\n",
    "if match:\n",
    "    print(match.group())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973f56c-f7f2-4864-89d1-e8089d5e34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_PREFIX = ['here are', 'here is', 'following are']\n",
    "\n",
    "df = \"here are responses\"\n",
    "\n",
    "for k in POSSIBLE_PREFIX:\n",
    "    if k in df.lower():\n",
    "        print(k)\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848ad7d-2576-4cb8-b129-b88f291af02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output_raw(raw_response):\n",
    "    \n",
    "    data = {}\n",
    "    string_json = []\n",
    "    for prefix in POSSIBLE_PREFIX:\n",
    "        if prefix in raw_response.lower():\n",
    "            string_json.append(prefix)\n",
    "            break\n",
    "\n",
    "    if string_json:\n",
    "        data['text'] = string_json\n",
    "    else:\n",
    "        data['text'] = raw_response\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "model_output_raw(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb91a43-f10d-4d09-a012-9cc1216d595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "s = '''\"\"\"\"Here is the NER output for the given medical passage:\\n\\n[{'T': 'diagnosis', 'E': 'pain'}, {'T': 'diagnosis', 'E': 'numbness'}, {'T': 'diagnosis', 'E': 'tingling'}, {'T': 'diagnosis', 'E': 'erotic dysfunction'}, {'T': 'diagnosis', 'E': 'weak dorsalis pedis'}, {'T': 'diagnosis', 'E': 'tibialis'}, {'T': 'diagnosis', 'E': 'popliteal'}, {'T': 'diagnosis', 'E': 'femoral pulses'}, {'branch' : 'Vascular', 'group': 'Arterial'}]\"\"\"\"'''\n",
    "\n",
    "pattern = r'(\\{(?:[^{}]|(?R))*\\}|\\[(?:[^[\\]]|(?R))*\\])'\n",
    "matches = re.findall(pattern, s)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3364e-6a61-4165-afb0-558f78eb1d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66d717-bd6e-4bbc-bfe1-1ee312a89cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubModel(model = \"google/flan-t5-xl\", api_key = \"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8505283-0433-48a7-931e-b4a8832fc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run('hi how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee821c-3689-4132-9487-e8dd18c7b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompter = Prompter('ner.jinja')\n",
    "\n",
    "# model = OpenAI(api_key = \"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\", model = \"gpt-4\")\n",
    "# pipe = Pipeline(prompter , model, structured_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17352c79-29b9-41c4-8ca3-d3df82f056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompter.generate('hi how are you', 'gpt-3.5-turbo', domain = 'aa', labels = 'aaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ba09b-1b9b-4dc7-97d7-1e79717c1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(\"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremitiess \"\"\", \n",
    "         domain = 'medical',\n",
    "         labels = 'diagnosis', \n",
    "         n_output_labels = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886b455-26d3-4268-9c31-20c3b8abab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'llamaa'\n",
    "\n",
    "\n",
    "\n",
    "# def find_sample_with_model(data, model_name):\n",
    "#     for sample in data:\n",
    "#         if model_name in sample['models']:\n",
    "#             return sample\n",
    "#     return None  # return None if no sample contains the given model\n",
    "\n",
    "def search_model(data, model_name):\n",
    "\n",
    "    all_models = []\n",
    "    for sample in data:\n",
    "        if model_name in sample['models']:\n",
    "            return sample\n",
    "        else:\n",
    "            all_models.extend(sample['models'])\n",
    "    raise ValueError(\n",
    "                f\"Model not found. Please choose the model from : {all_models}\"\n",
    "            )\n",
    "\n",
    "\n",
    "search_model(drt, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633729f-3530-4ac8-993a-615bb46343bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_generation import InferenceAPIAsyncClient\n",
    "\n",
    "client = InferenceAPIAsyncClient(\"tiiuae/falcon-7b-instruct\")\n",
    "response = await client.generate(\"give me medical entities from this parahraph in json format -- A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction. On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis, popliteal, and femoral pulses in both lower and and extremitiess\")\n",
    "print(response.generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c7d6d6-0bd8-4cb3-984d-ee00c23fb176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_generation.inference_api import deployed_models\n",
    "\n",
    "asd = deployed_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27e4862-b8c2-4bc9-8163-f0fcf84ad6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "asd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d6f50-535d-4e2a-a1dc-c9b01aa1fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptify import Prompter\n",
    "from promptify import Model, OpenAI,MockModel\n",
    "from promptify import Pipeline\n",
    "\n",
    "# template_ = \"\"\"please exaplain what is this\"\"\"\n",
    "\n",
    "\n",
    "# model = MockModel(api_key = 'random', model ='mock_model')\n",
    "# model.run(\"hi\")\n",
    "\n",
    "# model = OpenAI(api_key = \"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\", api_wait = 1, api_retry = 1, \n",
    "#             model = \"gpt-3.5-turbo\")\n",
    "# prompter = Prompter(template_, from_string = True)\n",
    "prompter = Prompter('ner.jinja')\n",
    "# chain = [prompter, prompter2]\n",
    "pipe = Pipeline(prompter , model, structured_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f0b85-0579-4465-845c-4e041f2ce732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "full_model_list = [model_['id'] for model_ in openai.Model.list()['data']]\n",
    "full_model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5367ea2-44a6-4bce-a151-8338bdb1b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supported_models():\n",
    "\n",
    "    completion_models = ['text-davinci-003',\n",
    "                            'davinci',\n",
    "                            'text-davinci-001',\n",
    "                            'ada',\n",
    "                            'text-curie-001',\n",
    "                            'text-ada-001',\n",
    "                            'text-babbage-001',\n",
    "                            'curie',\n",
    "                            'text-davinci-002']\n",
    "\n",
    "\n",
    "    chat_models  = ['gpt-4-0314',\n",
    "    'gpt-3.5-turbo-16k-0613',\n",
    "    'gpt-3.5-turbo-0301',\n",
    "    'gpt-3.5-turbo-16k',\n",
    "    'gpt-4',\n",
    "    'gpt-3.5-turbo',\n",
    "    'gpt-3.5-turbo-0613',\n",
    "    'gpt-4-0613']\n",
    "    \n",
    "    all_models = completion_models.extend(chat_models)\n",
    "\n",
    "    return {'chat_models': chat_models, 'completion_models': completion_models, 'all_models' :  all_models}\n",
    "\n",
    "\n",
    "[model for model_list in supported_models().values() for model in model_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195995ce-2eff-4521-827a-f239bfecd918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b72b7d1-965c-462c-a1e9-575f63f9358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(api_key = \"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\", model = \"text-babbage-001\")\n",
    "print(model.run(\"give me list of top 5 research scientists in AI field in json format\"))\n",
    "\n",
    "# model.model_output(mk, max_completion_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1cba7-d56f-43c5-a447-e58442ef7af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660d863-d272-4a72-9e12-bf225d9cdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "gh = Parser()\n",
    "gh.fit(str({'text': \"Hello! I'm an AI assistant, so I don't have feelings, but I'm here to help you. How can I assist you today?\", 'usage': {'prompt_tokens': 22, 'completion_tokens': 30, 'total_tokens': 52}}), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d87b9d-02ab-48e4-b891-6b5d9918a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1b95e-443b-4abb-82c5-b6b2e81e4384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71614c-29ab-445e-84eb-8de75b496de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(\"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremitiess \"\"\", domain = 'medical', labels = 'diagnosis', n_output_labels = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090dc95c-1eba-4959-9733-d55b798e66d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = OpenAI(api_key = \"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\", api_wait = 1, api_retry = 1, \n",
    "            model = \"gpt-3.5-turbo\")\n",
    "hf.run([\"hi how are you\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e6bea9-334e-4934-847a-34ff39f83c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_ = \"\"\"{%- if description is not none -%}\n",
    "{{ description }}\n",
    "{% endif -%}\n",
    "\n",
    "{%- if domain is not none -%}\n",
    "\n",
    "{%- if labels is not none -%}\n",
    "You are a highly intelligent and accurate {{ domain }} domain Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of {{ domain }} domain named entities in that given passage and classify into a set of following predefined entity types:\n",
    "{{ labels }}\n",
    "{%- else -%}\n",
    "You are a highly intelligent and accurate {{ domain }} domain Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of {{ domain }} domain named entities in that given passage and classify into a set of entity types.\n",
    "{%- endif -%}\n",
    "{% else %}\n",
    "{%- if labels is not none -%}\n",
    "You are a highly intelligent and accurate Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of named entities in that given passage and classify into a set of following predefined entity types:\n",
    "{{ labels }}\n",
    "{%- else -%}\n",
    "You are a highly intelligent and accurate Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of named entities in that given passage and classify into a set of entity types.\n",
    "{%- endif -%}\n",
    "{% endif -%}\n",
    "Your output format is only {{ output_format|default(\"[{'T': type of entity from predefined entity types, 'E': entity in the input text}},...,{{'branch' : Appropriate branch of the passage ,'group': Appropriate Group of the passage}]\") }} form, no other form.\n",
    "\n",
    "{% if examples is defined and examples|length > 0 -%}\n",
    "Examples:\n",
    "{% for sentence, label in examples %}\n",
    "Input: {{ sentence }}\n",
    "Output: [{{ label }}]\n",
    "{% endfor %}\n",
    "{% endif -%}\n",
    "\n",
    "Input: {{ text_input }}\n",
    "Output:\"\"\"\n",
    "\n",
    "tp = Prompter('ner.jinja')\n",
    "# tp.generate(text_input = 'Hi', domain = 'me', labels = 'aa', from_string = True)\n",
    "# model = Model(\n",
    "# print(tp.generate('ner.jinja', text_input = 'Hi')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15597bb4-eae3-47a5-856e-b822bd18367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_chain = [tp, tp, tp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8d462-77d0-4a54-a957-24a36387f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(prompt_chain, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2ad2f-9546-4306-89b0-4276e21ff7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(\"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremities \"\"\", domain = 'medical', labels = 'diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5f4de7-5430-4c7e-a2cd-f8047739e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "{%- if description is not none -%}\n",
    "{{ description }}\n",
    "{% endif -%}\n",
    "\n",
    "{%- if domain is not none -%}\n",
    "{%- if labels is not none -%}\n",
    "You are a highly intelligent and accurate {{ domain }} domain Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of {{ domain }} domain named entities in that given passage and classify into a set of following predefined entity types:\n",
    "{{ labels }}\n",
    "{%- else -%}\n",
    "You are a highly intelligent and accurate {{ domain }} domain Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of {{ domain }} domain named entities in that given passage and classify into a set of entity types.\n",
    "{%- endif -%}\n",
    "{% else %}\n",
    "{%- if labels is not none -%}\n",
    "You are a highly intelligent and accurate Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of named entities in that given passage and classify into a set of following predefined entity types:\n",
    "{{ labels }}\n",
    "{%- else -%}\n",
    "You are a highly intelligent and accurate Named-entity recognition(NER) system. You take Passage as input and your task is to recognize and extract specific types of named entities in that given passage and classify into a set of entity types.\n",
    "{%- endif -%}\n",
    "{% endif -%}\n",
    "Your output format is only {{ output_format|default(\"[{'T': type of entity from predefined entity types, 'E': entity in the input text}},...,{{'branch' : Appropriate branch of the passage ,'group': Appropriate Group of the passage}]\") }} form, no other form.\n",
    "\n",
    "{% if examples is defined and examples|length > 0 -%}\n",
    "Examples:\n",
    "{% for sentence, label in examples %}\n",
    "Input: {{ sentence }}\n",
    "Output: [{{ label }}]\n",
    "{% endfor %}\n",
    "{% endif -%}\n",
    "\n",
    "Input: {{ text_input }}\n",
    "Output:\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247cfad0-11b8-4309-9c6f-5b5f7cc0d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Sentiment analysis pipeline\n",
    "analyzer = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Question answering pipeline, specifying the checkpoint identifier\n",
    "oracle = pipeline(\n",
    "    \"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\"\n",
    ")\n",
    "\n",
    "# Named entity recognition pipeline, passing in a specific model and tokenizer\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "recognizer = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c68151-21ab-4eb1-b0b0-99ec400f27af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptify import Prompter\n",
    "from promptify import Model\n",
    "from promptify import pipeline\n",
    "\n",
    "\n",
    "prompter = Prompter(template, text_input, domain, labels)\n",
    "model    = Model(model_name, model_parameteres)\n",
    "output   = pipeline(prompter, model)\n",
    "\n",
    "\n",
    "or \n",
    "\n",
    "prompter = Prompter(template)\n",
    "model    = Model(model_name, aa)\n",
    "output   = Pipeline(prompter, model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c791f19-448b-47b2-bad6-26c17d329ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, prompter, model):\n",
    "        # Add logic here to perform operations with prompter and model\n",
    "        pass\n",
    "\n",
    "# Instantiate and use the Pipeline\n",
    "pipe = Pipeline()\n",
    "pipe.fit(prompter, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74452c-b201-471f-a91e-c0855a5cb6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b52ccc-a9e3-4bd3-9a99-0d61f6a67217",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Azure(api_key = '776adfa04e084cc69f2d58e33c684394',\n",
    "             api_base = 'https://airesearch-dev.openai.azure.com/',\n",
    "              api_type = 'azure',\n",
    "              api_version = '2023-03-15-preview',\n",
    "              engine = 'gpt35turbo',\n",
    "              model = 'gpt-35-turbo')\n",
    "\n",
    "model.run(\"give me medical entities from this parahraph in json format, no description only json -- A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction. On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis, popliteal, and femoral pulses in both lower and and extremitiess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5242e-1bc0-42f2-b8ac-557561dfd254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model_output(model.run(\"give me medical entities from this parahraph in json format, no description only json -- A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction. On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis, popliteal, and femoral pulses in both lower and and extremitiess\"), 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf5e23-52d8-4991-96fa-775028b5ed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://airesearch-dev.openai.azure.com/\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = '776adfa04e084cc69f2d58e33c684394'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# response = openai.ChatCompletion.create(\n",
    "#   engine=\"sdq_dq_gen_v2\", # replace this value with the deployment name you chose when you deployed the associated model.\n",
    "#   messages = [{\"role\":\"system\",\"content\":\"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"},{\"role\":\"user\",\"content\":\"How much is a PS5?\"},{\"role\":\"assistant\",\"content\":\"I apologize, but I do not have information about the prices of other gaming devices such as the PS5. My primary focus is to assist with issues regarding Xbox devices. Is there a specific issue you are having with your Xbox device that I may be able to help with?\"},{\"role\":\"user\",\"content\":\"I am interested in buying an Xbox?\"},{\"role\":\"assistant\",\"content\":\"Great! There are several Xbox models available in the market, including the Xbox Series X, Xbox Series S, and Xbox One. The Xbox Series X is the latest and most powerful console, while the Xbox Series S is a more affordable option that still offers great performance. The Xbox One is the previous generation console, but it still has a large library of games available to play.\\n\\nBefore purchasing an Xbox, you may want to consider factors such as your budget, the types of games you want to play, and whether you want to play games in 4K resolution. Once you have decided on a console, you can purchase it from a retailer or directly from the Xbox website. Let me know if you have any other questions or concerns!\"},{\"role\":\"user\",\"content\":\"Which models are 4K?\"},{\"role\":\"assistant\",\"content\":\"Both the Xbox Series X and Xbox One X support 4K resolution gaming. The Xbox Series S, on the other hand, supports up to 1440p resolution gaming, but it can upscale games to 4K. It's worth noting that in order to take advantage of 4K gaming, you'll need a 4K TV or monitor that supports HDR (High Dynamic Range) and HDMI 2.0 or higher.\"}],\n",
    "#   temperature=0,\n",
    "#   max_tokens=350,\n",
    "#   top_p=0.95,\n",
    "#   frequency_penalty=0,\n",
    "#   presence_penalty=0,\n",
    "#   stop=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# response = openai.Completion.create(\n",
    "#             model= 'gpt-35-turbo',\n",
    "#             prompt= 'Hi How are you?',\n",
    "#             temperature=0.7,\n",
    "#             max_tokens=350,\n",
    "#             engine = \"sdq_dq_gen_v2\",\n",
    "#             top_p=1,\n",
    "#             stop=[\"Stop Here\"],\n",
    "#             frequency_penalty=0,\n",
    "#             presence_penalty=0\n",
    "#             )\n",
    "\n",
    "# 2023-03-15-preview Swagger spec\n",
    "# 2022-12-01 Swagger spec\n",
    "# 2023-05-15 Swagger spec\n",
    "# 2023-06-01-preview Swagger spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f66d89a-d758-4028-b90e-e21ab2d06be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "import os\n",
    "import openai\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://airesearch-dev.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"776adfa04e084cc69f2d58e33c684394\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  engine=\"gpt35turbo\",\n",
    "  model = 'gpt35turbo',\n",
    "  messages = [{\"role\":\"system\",\"content\":\"You are an AI assistant that helps people find information.\"},{\"role\":\"user\",\"content\":\"Hello\"},{\"role\":\"assistant\",\"content\":\"Hello! How can I assist you today?\"}],\n",
    "  temperature=0.7,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73540a14-9022-476c-80d3-6730c6f518f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28300ad0-7ffc-44b9-8079-d06e346d5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "text = \"This is a test sentence.\"\n",
    "encoded_text = encoding.encode(text)\n",
    "decoded_text = encoding.decode(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbe6cc7-99a0-4a56-a13c-00ab82e45946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from huggingface_hub import model_info\n",
    "from promptify import Model\n",
    "from huggingface_hub.utils import (\n",
    "    RepositoryNotFoundError,\n",
    "    build_hf_headers,\n",
    "    hf_raise_for_status,\n",
    ")\n",
    "\n",
    "from promptify import __version__\n",
    "import requests\n",
    "\n",
    "\n",
    "class HubModel(Model):\n",
    "\n",
    "    name = \"HuggingFace\"\n",
    "    description = \"HuggingFace API for text completion using various models\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: Optional[str] = None,\n",
    "        model: str = \"google/flan-t5-xl\",\n",
    "        wait_for_model: bool = True,\n",
    "        use_cache: bool = True,\n",
    "        top_k: Optional[int] = None,\n",
    "        top_p: Optional[float] = None,\n",
    "        temperature: float = 1.0,\n",
    "        repetition_penalty: Optional[float] = None,\n",
    "        max_new_tokens: Optional[int] = 20,\n",
    "        max_time: Optional[float] = None,\n",
    "        num_return_sequences: int = 1,\n",
    "        do_sample: bool = False,\n",
    "        api_wait= 60,\n",
    "        api_retry= 6,\n",
    "        max_completion_length: int = 20,\n",
    "    ):\n",
    "        \n",
    "\n",
    "        self.set_key(api_key)\n",
    "        self.set_model(model)\n",
    "        \n",
    "        \n",
    "        super().__init__(self.api_key, self.model, api_wait, api_retry)\n",
    "\n",
    "        self.wait_for_model = wait_for_model\n",
    "        self.use_cache = use_cache\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "        self.temperature = temperature\n",
    "        self.repetition_penalty = repetition_penalty\n",
    "        self.max_new_tokens = max_new_tokens\n",
    "        self.max_time = max_time\n",
    "        self.num_return_sequences = num_return_sequences\n",
    "        self.do_sample = do_sample\n",
    "        self.max_completion_length = max_completion_length\n",
    "\n",
    "        self._verify_model()\n",
    "        self.set_key(self.api_key)\n",
    "\n",
    "    @classmethod\n",
    "    def supported_models(cls) -> Dict[str, str]:\n",
    "\n",
    "        response = requests.get(\n",
    "            \"https://huggingface.co/api/models?pipeline_tag=text2text-generation&sort=downloads&direction=-1\"\n",
    "        )\n",
    "\n",
    "        hf_raise_for_status(response)\n",
    "        \n",
    "        \n",
    "        models_text2text_generation = {\n",
    "            model: f\"check more details at https://huggingface.co/{model}\"\n",
    "            for model in sorted(item[\"id\"] for item in response.json())\n",
    "        }\n",
    "        \n",
    "        response_ = requests.get(\n",
    "            \"https://huggingface.co/api/models?pipeline_tag=text-generation&sort=downloads&direction=-1\"\n",
    "        )\n",
    "\n",
    "        hf_raise_for_status(response_)\n",
    "        \n",
    "        models_text2text = {\n",
    "            model: f\"check more details at https://huggingface.co/{model}\"\n",
    "            for model in sorted(item[\"id\"] for item in response_.json())\n",
    "        }\n",
    "        \n",
    "        models_text2text_generation.update(models_text2text)\n",
    "        return models_text2text_generation\n",
    "\n",
    "    def _verify_model(self):\n",
    "\n",
    "        if self.model not in self.supported_models():\n",
    "            raise ValueError(f\"Unsupported model: {self.model}\")\n",
    "\n",
    "    def set_key(self, api_key: Optional[str]):\n",
    "\n",
    "        self.api_key = api_key\n",
    "        self._headers = build_hf_headers(\n",
    "            token=api_key, library_name=\"promptify\", library_version=__version__\n",
    "        )\n",
    "\n",
    "    def set_model(self, model: str):\n",
    "\n",
    "        self.model = model\n",
    "        if self.model.startswith(\"https://\") and \"huggingface\" in self.model:\n",
    "            # User provided a URL pointing to a Inference Endpoint\n",
    "            self._url = self.model\n",
    "            self.model = self.model.split(\"models/\")[-1]\n",
    "        else:\n",
    "            self._url = self.get_endpoint()\n",
    "\n",
    "    def get_description(self) -> str:\n",
    "        return self.supported_models()[self.model]\n",
    "\n",
    "    def model_output(self, response: Dict, max_completion_length = None) -> Dict:\n",
    "        \n",
    "        return [item[\"generated_text\"] for item in response.json()]\n",
    "    \n",
    "    def model_output_raw(self, response):\n",
    "        return response.text\n",
    "    \n",
    "    \n",
    "    def get_endpoint(self) -> str:\n",
    "        try:\n",
    "            info = model_info(self.model, token=self.api_key)\n",
    "        except RepositoryNotFoundError:\n",
    "            raise ValueError(\n",
    "                f\"Model '{self.model}' does not exist on the Huggingface Hub. Please visit https://huggingface.co/models to\"\n",
    "                \" find a suitable model.\"\n",
    "            )\n",
    "\n",
    "        if info.pipeline_tag not in (\"text-generation\", \"text2text-generation\"):\n",
    "            raise ValueError(\n",
    "                f\"Cannot use model {self.model}. Pipeline is of type {info.pipeline_tag}. Expecting either\"\n",
    "                \" 'text-generation' or 'text2text-generation'.\"\n",
    "            )\n",
    "\n",
    "        return f\"https://api-inference.huggingface.co/pipeline/{info.pipeline_tag}/{self.model}\"\n",
    "\n",
    "    def get_parameters(\n",
    "        self,\n",
    "    ) -> Dict[str, Union[str, int, float, List[str], Dict[str, int]]]:\n",
    "\n",
    "        return {\n",
    "            \"wait_for_model\": self.wait_for_model,\n",
    "            \"use_cache\": self.use_cache,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"repetition_penalty\": self.repetition_penalty,\n",
    "            \"max_new_tokens\": self.max_new_tokens,\n",
    "            \"max_time\": self.max_time,\n",
    "            \"num_return_sequences\": self.num_return_sequences,\n",
    "            \"do_sample\": self.do_sample,\n",
    "        }\n",
    "\n",
    "    def run(self, prompts: List[str]) -> List[Optional[str]]:\n",
    "        result = []\n",
    "        for prompt in prompts:\n",
    "            response = requests.post(\n",
    "                self._url,\n",
    "                headers=self._headers,\n",
    "                json={\n",
    "                    \"inputs\": prompt,\n",
    "                    \"options\": {\n",
    "                        \"wait_for_model\": self.wait_for_model,\n",
    "                        \"use_cache\": self.use_cache,\n",
    "                    },\n",
    "                    \"parameters\": {\n",
    "                        \"top_k\": self.top_k,\n",
    "                        \"top_p\": self.top_p,\n",
    "                        \"temperature\": self.temperature,\n",
    "                        \"repetition_penalty\": self.repetition_penalty,\n",
    "                        \"max_new_tokens\": self.max_new_tokens,\n",
    "                        \"max_time\": self.max_time,\n",
    "                        \"num_return_sequences\": self.num_return_sequences,\n",
    "                        \"do_sample\": self.do_sample,\n",
    "                    },\n",
    "                },\n",
    "            )\n",
    "            hf_raise_for_status(response)\n",
    "            result.append(response)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91b6fe-6564-4933-8a73-d75c01f32e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_hf_headers(\n",
    "            token='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', library_name=\"promptify\", library_version= '0.1'\n",
    "        )\n",
    "\n",
    "\n",
    "def set_model(self, model: str):\n",
    "\n",
    "\n",
    "    if self.model.startswith(\"https://\") and \"huggingface\" in self.model:\n",
    "        # User provided a URL pointing to a Inference Endpoint\n",
    "        self._url = self.model\n",
    "        self.model = self.model.split(\"models/\")[-1]\n",
    "    else:\n",
    "        self._url = self.get_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d250f-b075-4e58-9620-efcb059234c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34788bd4-bb28-4346-bd5e-b9dba439036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = model_info(\"google/flan-t5-xl\", token='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')\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6339a-153d-4e9f-9152-3fcec198012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import Dict, List, Optional, Tuple, Union\n",
    "# from huggingface_hub import model_info\n",
    "# from promptify import Model\n",
    "from huggingface_hub.utils import (\n",
    "    RepositoryNotFoundError,\n",
    "    build_hf_headers,\n",
    "    hf_raise_for_status,\n",
    ")\n",
    "\n",
    "# from promptify import __version__\n",
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "            \"https://huggingface.co/api/models?pipeline_tag=text2text-generation&sort=downloads&direction=-1\"\n",
    "        )\n",
    "\n",
    "hf_raise_for_status(response)\n",
    "        \n",
    "models_text2text_generation = {\n",
    "            model: f\"check more details at https://huggingface.co/{model}\"\n",
    "            for model in sorted(item[\"id\"] for item in response.json())\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532b7d7b-7fd7-4acc-907f-e99b7a6d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ = requests.get(\n",
    "            \"https://huggingface.co/api/models?pipeline_tag=text-generation&sort=downloads&direction=-1\")\n",
    "\n",
    "hf_raise_for_status(response_)\n",
    "\n",
    "models_text2text = {\n",
    "            model: f\"check more details at https://huggingface.co/{model}\"\n",
    "            for model in sorted(item[\"id\"] for item in response_.json())\n",
    "        }\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5124a-33af-4a79-a34f-509bbc5de185",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_text2text_generation.update(models_text2text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca14474-e6a5-4151-aaac-a826b7a95c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(models_text2text_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647d124-7412-4765-b537-5fcfeefb1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_generation import InferenceAPIClient\n",
    "\n",
    "prompt = \"\"\"give me named entities from this sentences, return output only in json format {'T': 'entity'}\"\"\"\n",
    "\n",
    "sen = prompt + \"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremities\"\"\"\n",
    "\n",
    "\n",
    "client = InferenceAPIClient(\"tiiuae/falcon-7b-instruct\", token= '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')\n",
    "text = client.generate(sen).generated_text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3e6646-1e1d-442b-98d3-206d73a70874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "\n",
    "anthropic = Anthropic(\n",
    "    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "    api_key=\"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\",\n",
    ")\n",
    "\n",
    "completion = anthropic.completions.create(\n",
    "    model=\"claude-instant-1\",\n",
    "    stop_sequences = ['this'],\n",
    "    max_tokens_to_sample=300,\n",
    "    temperature = 1,\n",
    "    top_p = 0.7,\n",
    "    top_k = 5,\n",
    "    prompt=f\"{HUMAN_PROMPT} who are you, what is your model name {AI_PROMPT}\",\n",
    ")\n",
    "print(completion.completion)\n",
    "\n",
    "\n",
    "# {\n",
    "#   \"stop_sequences\": [\n",
    "#     \"this\"\n",
    "#   ],\n",
    "#   \"prompt\": \"this is a prompt\",\n",
    "#   \"model\": \"claude-2\",\n",
    "#   \"max_tokens_to_sample\": 245,\n",
    "#   \"temperature\": 0.7,\n",
    "#   \"top_p\": 0.7,\n",
    "#   \"top_k\": 5\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "# self,\n",
    "#         *,\n",
    "#         max_tokens_to_sample: int,\n",
    "#         model: str,\n",
    "#         prompt: str,\n",
    "#         metadata: completion_create_params.CompletionRequestNonStreamingMetadata | NotGiven = NOT_GIVEN,\n",
    "#         stop_sequences: List[str] | NotGiven = NOT_GIVEN,\n",
    "#         stream: Literal[False] | NotGiven = NOT_GIVEN,\n",
    "#         temperature: float | NotGiven = NOT_GIVEN,\n",
    "#         top_k: int | NotGiven = NOT_GIVEN,\n",
    "#         top_p: float | NotGiven = NOT_GIVEN,\n",
    "#         # Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\n",
    "#         # The extra values given here take precedence over values defined on the client or passed to this method.\n",
    "#         extra_headers: Headers | None = None,\n",
    "#         extra_query: Query | None = None,\n",
    "#         extra_body: Body | None = None,\n",
    "#         timeout: float | None | NotGiven = 600,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c9935-37e0-4c43-8886-5c2c01522a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c649f8-0098-45c6-b47b-a77d58706f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_generation.inference_api import deployed_models\n",
    "print(deployed_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010bbcd-f979-4a01-b3fe-cbcad95f9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(InferenceAPIClient.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5759511-d340-465c-b3bc-092e4b166f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "from promptify import Parser\n",
    "from promptify import Model\n",
    "\n",
    "class AnthropicModel(Model):\n",
    "    name = \"Anthropic\"\n",
    "    description = \"Anthropic API for text completion using Claude model\"\n",
    "\n",
    "    SUPPORTED_MODELS = set(\n",
    "        [\n",
    "            \"claude-instant-1\",\n",
    "            \"claude-2\"\n",
    "        ]\n",
    "    )\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_key: str,\n",
    "        model: str = \"claude-instant-1\",\n",
    "        temperature: float = 1,\n",
    "        top_p: float = 0.7,\n",
    "        top_k: int = 5,\n",
    "        max_tokens_to_sample: int = 300,\n",
    "        stop_sequences: Optional[Union[str, List[str]]] = [\"\\n\\nHuman:\"],\n",
    "        api_wait=60,\n",
    "        api_retry=6,\n",
    "        max_completion_length: int = 20\n",
    "    ):\n",
    "        super().__init__(api_key, model, api_wait, api_retry)\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.top_p = top_p\n",
    "        self.top_k = top_k\n",
    "        self.max_tokens_to_sample = max_tokens_to_sample\n",
    "        self.max_completion_length = max_completion_length\n",
    "        self.stop_sequences = stop_sequences\n",
    "        self.set_key(api_key)\n",
    "        self._verify_model()\n",
    "        self.parameters = self.get_parameters()\n",
    "        self._initialize_parser()\n",
    "\n",
    "    def set_key(self, api_key: str):\n",
    "        \n",
    "        self._anthropic = Anthropic(api_key=api_key)\n",
    "\n",
    "    def _verify_model(self):\n",
    "        if self.model not in self.SUPPORTED_MODELS:\n",
    "            raise ValueError(f\"Unsupported model: {self.model}\")\n",
    "\n",
    "    def set_model(self, model: str):\n",
    "        self.model = model\n",
    "        self._verify_model()\n",
    "\n",
    "    def _initialize_parser(self):\n",
    "        self.parser = Parser()\n",
    "\n",
    "    def supported_models(self):\n",
    "        return list(self.SUPPORTED_MODELS)\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"top_k\": self.top_k,\n",
    "            \"max_tokens_to_sample\": self.max_tokens_to_sample,\n",
    "            \"stop_sequences\": self.stop_sequences,\n",
    "        }\n",
    "\n",
    "    def get_description(self):\n",
    "        return self.description\n",
    "\n",
    "    def get_endpoint(self):\n",
    "        return self.model\n",
    "\n",
    "    def run(self, prompt: str):\n",
    "        self.parameters[\"prompt\"] = f\"{HUMAN_PROMPT} {prompt} {AI_PROMPT}\"\n",
    "        response = self._anthropic.completions.create(\n",
    "            model=self.model,\n",
    "            **self.parameters,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def model_output_raw(self, response: Dict) -> Dict:\n",
    "        data = {}\n",
    "        data[\"text\"] = response.completion.strip(\" \\n\")\n",
    "        return data\n",
    "\n",
    "    def model_output(self, response) -> Dict:\n",
    "        data = self.model_output_raw(response)\n",
    "        data[\"parsed\"] = self.parser.fit(data[\"text\"], self.max_completion_length)\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4665ea01-8eed-4576-9fae-4de3a6f0b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnthropicModel(api_key=\"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\",\n",
    "                      model = 'claude-2')\n",
    "\n",
    "\n",
    "prompt = \"\"\"give me named entities from this sentences, return output only in json format {'T': 'entity'}\"\"\"\n",
    "\n",
    "sen = prompt + \"\"\"A 62-year-old white man complained of pain, numbness, and tingling in both lower extremities that is increased\n",
    "by walking more than one-half a block for the past 6 months. He also complains of erectile dysfunction.\n",
    "On physical examination, his blood pressure is 110/80, but he demonstrates weak dorsalis pedis, tibialis,\n",
    "popliteal, and femoral pulses in both lower and and extremities\"\"\"\n",
    "\n",
    "result = model.run(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61cca6-5bf7-420c-80b6-8e44f37083ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "\n",
    "pattern = r'(\\{(?:[^{}]|(?R))*\\}|\\[(?:[^[\\]]|(?R))*\\])'\n",
    "text = \"Based on your request, Here is the output for the given medical passage:\\n\\n[{'T': 'diagnosis', 'E': 'pain'}, {'T': 'diagnosis', 'E': 'numbness'}, {'T': 'diagnosis', 'E': 'tingling'}, {'T': 'diagnosis', 'E': 'erectile dysfunction'}, {'T': 'diagnosis', 'E': 'weak dorsalis pedis'}, {'T': 'diagnosis', 'E': 'tibialis'}, {'T': 'diagnosis', 'E': 'popliteal'}, {'T': 'diagnosis', 'E': 'femoral pulses'}, {'branch' : 'Vascular', 'group': 'Arterial' \"\n",
    "matches = regex.findall(pattern, text)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b8d9a-3a23-43b0-827a-b921d36a152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('w5zH0UbislRCxITc8UN8pJRQCcdcGq6nJZ8Nm4YL') # This is your trial API key\n",
    "response = co.generate(\n",
    "  model='command',\n",
    "  prompt='Suggest three alternative titles with a better marketing copy for the following blog.\\n\\nThe tone of the alternative titles is: Inspirational\\nBlog Title: Learning to Play Chess\\nAlternative Blog Titles:',\n",
    "  max_tokens=200,\n",
    "  temperature=0.9,\n",
    "  k=0,\n",
    "  stop_sequences=[],\n",
    "  return_likelihoods='NONE')\n",
    "print('Prediction: {}'.format(response.generations[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0810ec-8fce-4891-a823-bac91db5c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "\n",
    "def extract_string_json(text):\n",
    "    pattern = r'(\\[\\{.*?\\}\\])'\n",
    "    match = regex.search(pattern, text)\n",
    "    if match:\n",
    "        try:\n",
    "            return match.group()\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise f\"Error decoding JSON: {e}\"\n",
    "\n",
    "# Example usage:\n",
    "text = 'some text before [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}] some text after'\n",
    "json_objects = extract_and_load_json(text)\n",
    "print(json_objects)\n",
    "# In this script, we use the regex pattern (\\[\\{.*?\\}\\]) to find a JSON object embedded in the text. We then try to parse this object as JSON. If the parsing fails, an error message is printed and the function returns None.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f217622-3be2-49a0-8922-8b28a023e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "\n",
    "\n",
    "def extract_json_object(text):\n",
    "    pattern = r'(\\[\\{.*?\\}\\])'\n",
    "    match = regex.search(pattern, text)\n",
    "    return match.group()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0762e0-8cd5-493d-8919-9321f6572116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import regex\n",
    "\n",
    "def extract_string_json(text):\n",
    "    pattern = r'(\\[\\{.*?\\}\\])'\n",
    "    match = regex.search(pattern, text)\n",
    "    if match:\n",
    "        try:\n",
    "            return match.group()\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise f\"Error decoding JSON: {e}\"\n",
    "            \n",
    "            \n",
    "extract_string_json(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68baef1-85d0-41d2-b6ce-8160d74dac38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
